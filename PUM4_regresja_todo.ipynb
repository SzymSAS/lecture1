{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "zaczytanie niezbędnych bibliotek"
      ],
      "metadata": {
        "id": "G-H2tGj_rHHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "LXSU9M5cpqjr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "zaczytaj dane dotyczace sprzedazy"
      ],
      "metadata": {
        "id": "1awwEGFVqI0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install kagglehub[pandas-datasets]\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Set the path to the file you'd like to load\n",
        "file_path = \"Salary Data.csv\"\n",
        "\n",
        "# Load the latest version\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"rkiattisak/salaly-prediction-for-beginer\",\n",
        "  file_path,\n",
        "  # Provide any additional arguments like\n",
        "  # sql_query or pandas_kwargs. See the\n",
        "  # documenation for more information:\n",
        "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
        ")\n",
        "\n",
        "print(\"First 5 records:\", df.head())"
      ],
      "metadata": {
        "id": "Sm2mgUpAq7Gp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a307b8-2a1a-4348-a820-c03307b75e8a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-72cc2aa30810>:9: DeprecationWarning: load_dataset is deprecated and will be removed in future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rkiattisak/salaly-prediction-for-beginer?dataset_version_number=1&file_name=Salary Data.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18.9k/18.9k [00:00<00:00, 26.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 records:     Age  Gender Education Level          Job Title  Years of Experience  \\\n",
            "0  32.0    Male      Bachelor's  Software Engineer                  5.0   \n",
            "1  28.0  Female        Master's       Data Analyst                  3.0   \n",
            "2  45.0    Male             PhD     Senior Manager                 15.0   \n",
            "3  36.0  Female      Bachelor's    Sales Associate                  7.0   \n",
            "4  52.0    Male        Master's           Director                 20.0   \n",
            "\n",
            "     Salary  \n",
            "0   90000.0  \n",
            "1   65000.0  \n",
            "2  150000.0  \n",
            "3   60000.0  \n",
            "4  200000.0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocessing\n",
        "\n",
        "1.   sprawdż typy danych\n",
        "2.   zmien etykiedy na zmienne liczbowe\n",
        "3. w przypadku brakujacych danych uzupelnij (w przypadku etykiet) najczesciej wystepującą wartością lub średnią wartością\n",
        "\n"
      ],
      "metadata": {
        "id": "xVJo9AwurLNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())  # Wyświetla informacje o typach danych i brakujących wartościach"
      ],
      "metadata": {
        "id": "gCa-ZzXqr2He",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05dab899-ca13-4cf6-c491-3a2edaef41d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 375 entries, 0 to 374\n",
            "Data columns (total 6 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   Age                  373 non-null    float64\n",
            " 1   Gender               373 non-null    object \n",
            " 2   Education Level      373 non-null    object \n",
            " 3   Job Title            373 non-null    object \n",
            " 4   Years of Experience  373 non-null    float64\n",
            " 5   Salary               373 non-null    float64\n",
            "dtypes: float64(3), object(3)\n",
            "memory usage: 17.7+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Inicjalizacja encodera\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Przekształcenie kolumn kategorycznych na liczby\n",
        "for column in df.columns:\n",
        "  if df[column].dtype == 'object':\n",
        "    df[column] = label_encoder.fit_transform(df[column])\n",
        "\n",
        "print(df.head())  # Podgląd danych po transformacji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPPEHzNhZs2E",
        "outputId": "f8024757-27e9-474d-cab3-5de35b3f2854"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Age  Gender  Education Level  Job Title  Years of Experience    Salary\n",
            "0  32.0       1                0        159                  5.0   90000.0\n",
            "1  28.0       0                1         17                  3.0   65000.0\n",
            "2  45.0       1                2        130                 15.0  150000.0\n",
            "3  36.0       0                0        101                  7.0   60000.0\n",
            "4  52.0       1                1         22                 20.0  200000.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5u7OO6wpkRgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podziel zbiór danych na testowy i treningowy w stosunku 30/70"
      ],
      "metadata": {
        "id": "ru2yFiYJr2jF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Definiujemy cechy (X) i zmienną docelową (y)\n",
        "X = df.drop(columns=[\"Salary\"])  # Wszystkie kolumny poza Salary to cechy\n",
        "y = df[\"Salary\"]  # Zmienna docelowa\n",
        "\n",
        "# Podział na zbiór treningowy (70%) i testowy (30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Sprawdzenie rozmiaru zbiorów\n",
        "print(f\"Rozmiar zbioru treningowego: {X_train.shape[0]} próbek\")\n",
        "print(f\"Rozmiar zbioru testowego: {X_test.shape[0]} próbek\")"
      ],
      "metadata": {
        "id": "Qa3i7JvesOF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c63233a-e937-4e10-d84b-0d717b9bd3cb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rozmiar zbioru treningowego: 262 próbek\n",
            "Rozmiar zbioru testowego: 113 próbek\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stworz model regresji liniowej korzystajac z parametrów domyślnych\n",
        "Przykład dokumentacji: https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py"
      ],
      "metadata": {
        "id": "RFcl8kJdsQHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "# Import SimpleImputer from sklearn.impute\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Create an imputer to fill missing values with the mean\n",
        "imputer = SimpleImputer(strategy='mean')  # You can use 'median' or 'most_frequent' as well\n",
        "\n",
        "# Fit the imputer on the training data and transform both training and testing data\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "imputer_y = SimpleImputer(strategy='mean')\n",
        "\n",
        "y_train = imputer_y.fit_transform(y_train.values.reshape(-1, 1)) # Reshape to 2D for imputer\n",
        "y_train = y_train.ravel()\n",
        "\n",
        "# Now you can train your model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predykcja na zbiorze testowym\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Wyświetlenie współczynników regresji\n",
        "print(\"Współczynniki regresji:\", model.coef_)\n",
        "print(\"Wartość intercept (punkt przecięcia):\", model.intercept_)"
      ],
      "metadata": {
        "id": "GQSgW39Tsgtz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b68a0ff-dfad-441e-ff86-3b82becdc1cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Współczynniki regresji: [ 3086.3742258   5942.18491947 13933.42430929    25.56102669\n",
            "  2686.85296315]\n",
            "Wartość intercept (punkt przecięcia): -55422.089219414614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Replace infinite values with NaN\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Create an imputer to fill missing values with the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Fit the imputer on the data and transform it\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# calculating VIF for each feature\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X_imputed, i)\n",
        "                  for i in range(len(X.columns))]\n",
        "print(vif_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCXmAXMCNKTZ",
        "outputId": "57dca6fa-6258-44ce-ffe0-815a84e258e9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               feature        VIF\n",
            "0                  Age  15.129201\n",
            "1               Gender   2.047736\n",
            "2      Education Level   2.330338\n",
            "3            Job Title   4.892569\n",
            "4  Years of Experience   9.426853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ocen model na zbiorze testowym za pomocą miar: średni błąd kwadratowy, średni błąd absolutny, wynik wyjaśnionej wariancji"
      ],
      "metadata": {
        "id": "iuqRGy8Dshn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = imputer_y.transform(y_test.reshape(-1, 1))\n",
        "y_test = y_test.ravel()\n",
        "\n",
        "# Obliczanie metryk oceny modelu\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "evs = explained_variance_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(\"Średni błąd kwadratowy (MSE):\", mse)\n",
        "print(\"Średni błąd absolutny (MAE):\", mae)\n",
        "print(\"Wynik R^2:\", r2)\n",
        "print(\"Wynik wyjaśnionej wariancji (EVS):\", evs)"
      ],
      "metadata": {
        "id": "rNnuBQvot5OT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "620a92c3-2d3e-40d4-b234-524494f6b082"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Średni błąd kwadratowy (MSE): 251867808.61881605\n",
            "Średni błąd absolutny (MAE): 10980.545681608131\n",
            "Wynik R^2: 0.8819044534150401\n",
            "Wynik wyjaśnionej wariancji (EVS): 0.8827891675163093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "spróbuj poprawić model, zacznij od danych, sprawdz korelacje, znormalizuj"
      ],
      "metadata": {
        "id": "ExaOoOu5u6q_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UrpqL3sLvH4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_IzPHcqJvzCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zbuduj model regresji odpornej i przetestuj jego predykcje"
      ],
      "metadata": {
        "id": "YVWhFj-mvRw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wykreś przewidziane i faktyczne wartości obu modeli (przykład w dokumentacji: https://scikit-learn.org/stable/auto_examples/ensemble/plot_voting_regressor.html#sphx-glr-auto-examples-ensemble-plot-voting-regressor-py)"
      ],
      "metadata": {
        "id": "FuME6rMZt53Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Check for Correlations\n",
        "correlation_matrix = df.corr()\n",
        "print(\"Correlation Matrix:\\n\", correlation_matrix)\n",
        "\n",
        "# Identify highly correlated features (e.g., correlation > 0.8 or < -0.8)\n",
        "# You might need to manually inspect the correlation matrix or set a threshold\n",
        "\n",
        "# 2. Normalize the Data\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop(columns=[\"Salary\"])\n",
        "y = df[\"Salary\"]\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Impute missing values before scaling\n",
        "imputer = SimpleImputer(strategy='mean')  # or 'median', 'most_frequent'\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "# Apply StandardScaler for normalization\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 3. Re-train the Model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Evaluate the Improved Model\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "evs = explained_variance_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nModel Evaluation with Normalization:\")\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)\n",
        "print(\"EVS:\", evs)"
      ],
      "metadata": {
        "id": "5V6NZWFHuqlE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "outputId": "40bd19d3-ec57-436c-d013-300ef7ecb9ce"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation Matrix:\n",
            "                           Age    Gender  Education Level  Job Title  \\\n",
            "Age                  1.000000 -0.020324         0.562693   0.117629   \n",
            "Gender              -0.020324  1.000000         0.008677   0.041562   \n",
            "Education Level      0.562693  0.008677         1.000000   0.127791   \n",
            "Job Title            0.117629  0.041562         0.127791   1.000000   \n",
            "Years of Experience  0.979128  0.002884         0.590863   0.100162   \n",
            "Salary               0.922335  0.071106         0.670371   0.136206   \n",
            "\n",
            "                     Years of Experience    Salary  \n",
            "Age                             0.979128  0.922335  \n",
            "Gender                          0.002884  0.071106  \n",
            "Education Level                 0.590863  0.670371  \n",
            "Job Title                       0.100162  0.136206  \n",
            "Years of Experience             1.000000  0.930338  \n",
            "Salary                          0.930338  1.000000  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input y contains NaN.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-de04d251e071>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# 3. Re-train the Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# 4. Evaluate the Improved Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         X, y = validate_data(\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1385\u001b[0m     )\n\u001b[1;32m   1386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1387\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1395\u001b[0m     \u001b[0;34m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m         y = check_array(\n\u001b[0m\u001b[1;32m   1398\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zmodyfikuj kod, zeby zwizualizować wynik lepszego z modeli"
      ],
      "metadata": {
        "id": "RODeXgYlusPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import PredictionErrorDisplay\n",
        "\n",
        "fig, axs = plt.subplots(ncols=2, figsize=(8, 4))\n",
        "PredictionErrorDisplay.from_predictions(\n",
        "    y,\n",
        "    y_pred=y_pred,\n",
        "    kind=\"actual_vs_predicted\",\n",
        "    subsample=100,\n",
        "    ax=axs[0],\n",
        "    random_state=0,\n",
        ")\n",
        "axs[0].set_title(\"Actual vs. Predicted values\")\n",
        "PredictionErrorDisplay.from_predictions(\n",
        "    y,\n",
        "    y_pred=y_pred,\n",
        "    kind=\"residual_vs_predicted\",\n",
        "    subsample=100,\n",
        "    ax=axs[1],\n",
        "    random_state=0,\n",
        ")\n",
        "axs[1].set_title(\"Residuals vs. Predicted Values\")\n",
        "fig.suptitle(\"Plotting cross-validated predictions\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DLVd2VkAuySx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6P2u6x9qsObf"
      }
    }
  ]
}